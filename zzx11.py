# -*- coding: utf-8 -*-
"""
ä¼é¹…åˆ†ç±»å™¨ - ç›¸å¯¹è·¯å¾„ç‰ˆ
ç‰¹ç‚¹ï¼šæ‰€æœ‰è·¯å¾„æ”¹ä¸ºç›¸å¯¹è·¯å¾„ï¼Œæ— éœ€ä¾èµ–ç»å¯¹è·¯å¾„D:/streamlit_env
"""

import streamlit as st
import pickle
import pandas as pd
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# ============================ å…¨å±€é…ç½®ï¼ˆå…¨ç›¸å¯¹è·¯å¾„ï¼Œæ— ç»å¯¹è·¯å¾„ä¾èµ–ï¼‰ ============================
st.set_page_config(page_title="ä¼é¹…åˆ†ç±»å™¨", page_icon="ğŸ§", layout="wide")

# æ ¸å¿ƒä¿®æ”¹ï¼šæ‰€æœ‰è·¯å¾„æ”¹ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆä»£ç æ–‡ä»¶ä¸æ•°æ®é›†/å›¾ç‰‡åœ¨åŒä¸€ç›®å½•ï¼‰
# æ•°æ®é›†ç›¸å¯¹è·¯å¾„ï¼šç›´æ¥å†™æ–‡ä»¶åï¼ˆå› æ•°æ®é›†åœ¨D:/streamlit_envï¼Œä»£ç ä¹Ÿåœ¨è¯¥ç›®å½•ï¼‰
DATA_PATH = "(ä¼é¹…è¯†åˆ«æ•°æ®)penguins-chinese.csv"
# æ¨¡å‹æ–‡ä»¶ç›¸å¯¹è·¯å¾„
MODEL_PATH = "rfc_model.pkl"
SPECIES_MAP_PATH = "output_uniques.pkl"
# ç‰©ç§å›¾ç‰‡ç›¸å¯¹è·¯å¾„ï¼ˆå›¾ç‰‡ä¸ä»£ç åœ¨åŒä¸€ç›®å½•ï¼‰
SPECIES_IMG_MAP = {
    "é˜¿å¾·åˆ©ä¼é¹…": "ADELIE.png",
    "å¸½å¸¦ä¼é¹…": "CHINSTRAP.png",
    "å·´å¸ƒäºšä¼é¹…": "GENTOO.png"
}
# Logoå’Œåˆé›†å›¾ç›¸å¯¹è·¯å¾„
LOGO_IMG = "right_logo.png"
PENGUINS_ALL_IMG = "penguins_all.png"

# æ•°æ®ä¸­å®é™…å²›å±¿
ACTUAL_ISLANDS = ["æ¯”æ–¯ç§‘ç¾¤å²›", "å¾·é‡Œå§†å²›", "æ‰˜å°”æ£®å²›"]
predict_result_species = None
predict_result_img = None

# ============================ å·¥å…·å‡½æ•°ï¼ˆé€‚é…ç›¸å¯¹è·¯å¾„ï¼‰ ============================
def check_file_exists(file_path, file_type="æ–‡ä»¶"):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰"""
    if not os.path.exists(file_path):
        st.error(f"âŒ æœªæ‰¾åˆ°{file_type}ï¼š{file_path}")
        st.info(f"ğŸ’¡ è¯·ç¡®ä¿{file_type}ä¸ä»£ç æ–‡ä»¶ï¼ˆqwq.pyï¼‰åœ¨åŒä¸€ç›®å½•ï¼")
        return False
    return True

def check_species_images():
    """æ£€æŸ¥ç‰©ç§å›¾ç‰‡æ˜¯å¦å­˜åœ¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰"""
    missing = []
    for species, img_path in SPECIES_IMG_MAP.items():
        if not os.path.exists(img_path):
            missing.append(f"{species}çš„å›¾ç‰‡ï¼š{img_path}")
    if missing:
        st.warning("âš ï¸ ä»¥ä¸‹å›¾ç‰‡ä¸ä»£ç ä¸åœ¨åŒä¸€ç›®å½•ï¼ˆä¸å½±å“é¢„æµ‹ï¼Œä»…å½±å“æ˜¾ç¤ºï¼‰ï¼š")
        for img in missing:
            st.write(f"- {img}")
    return missing

def get_correct_image(species_name):
    """è·å–ç‰©ç§å›¾ç‰‡ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰"""
    if species_name not in SPECIES_IMG_MAP:
        default_img = f"https://picsum.photos/300/300?{species_name}"
        return default_img, f"æœªè¯†åˆ«ç‰©ç§ï¼š{species_name}ï¼ˆç”¨é»˜è®¤å›¾æ›¿ä»£ï¼‰"
    
    img_path = SPECIES_IMG_MAP[species_name]
    if os.path.exists(img_path):
        return img_path, f"æˆåŠŸåŠ è½½{species_name}å›¾ç‰‡ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰"
    else:
        default_img = f"https://picsum.photos/300/300?{species_name}"
        return default_img, f"ç¼ºå¤±{species_name}å›¾ç‰‡ï¼š{img_path}ï¼ˆç”¨é»˜è®¤å›¾æ›¿ä»£ï¼‰"

# ============================ æ ¸å¿ƒåŠŸèƒ½å‡½æ•°ï¼ˆé€‚é…ç›¸å¯¹è·¯å¾„ï¼‰ ============================
def load_and_preprocess_data():
    """åŠ è½½æ•°æ®é›†ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰"""
    global ACTUAL_ISLANDS
    # å…ˆæ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    if not check_file_exists(DATA_PATH, "æ•°æ®é›†"):
        return None, None, None
    
    # è¯»å–æ•°æ®é›†ï¼ˆgbkç¼–ç ï¼‰
    try:
        df = pd.read_csv(DATA_PATH, encoding="gbk")
        st.success(f"âœ… æˆåŠŸè¯»å–æ•°æ®é›†ï¼ˆç›¸å¯¹è·¯å¾„ï¼š{DATA_PATH}ï¼‰")
    except Exception as e:
        st.error(f"âŒ è¯»å–æ•°æ®é›†å¤±è´¥ï¼š{str(e)}")
        return None, None, None
    
    # æ•°æ®æ¸…æ´—
    df = df.dropna(subset=["ä¼é¹…çš„ç§ç±»", "ä¼é¹…æ –æ¯çš„å²›å±¿", "å–™çš„é•¿åº¦", "å–™çš„æ·±åº¦", "ç¿…è†€çš„é•¿åº¦", "èº«ä½“è´¨é‡", "æ€§åˆ«"])
    df = df.reset_index(drop=True)
    
    # åŒæ­¥å²›å±¿åç§°
    data_islands = df["ä¼é¹…æ –æ¯çš„å²›å±¿"].unique()
    if not set(data_islands).issubset(set(ACTUAL_ISLANDS)):
        ACTUAL_ISLANDS = list(data_islands)
        st.info(f"â„¹ï¸ æ•°æ®é›†åŒ…å«å²›å±¿ï¼š{ACTUAL_ISLANDS}")
    
    # åˆ—åæ˜ å°„
    df.rename(columns={
        "ä¼é¹…çš„ç§ç±»": "ç‰©ç§",
        "ä¼é¹…æ –æ¯çš„å²›å±¿": "å²›å±¿",
        "å–™çš„é•¿åº¦": "å–™é•¿åº¦(mm)",
        "å–™çš„æ·±åº¦": "å–™æ·±åº¦(mm)",
        "ç¿…è†€çš„é•¿åº¦": "é³é•¿(mm)",
        "èº«ä½“è´¨é‡": "ä½“é‡(g)"
    }, inplace=True)
    
    # ç‰¹å¾ç¼–ç 
    X = pd.get_dummies(df[["å–™é•¿åº¦(mm)", "å–™æ·±åº¦(mm)", "é³é•¿(mm)", "ä½“é‡(g)", "å²›å±¿", "æ€§åˆ«"]], 
                      columns=["å²›å±¿", "æ€§åˆ«"], drop_first=False)
    le = LabelEncoder()
    y = le.fit_transform(df["ç‰©ç§"])
    species_map = {idx: name for idx, name in enumerate(le.classes_)}
    
    return X, y, species_map

def train_or_load_model():
    """åŠ è½½/è®­ç»ƒæ¨¡å‹ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰"""
    # å…ˆæ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    model_exists = os.path.exists(MODEL_PATH) and os.path.exists(SPECIES_MAP_PATH)
    if model_exists:
        try:
            with open(MODEL_PATH, "rb") as f:
                model = pickle.load(f)
            with open(SPECIES_MAP_PATH, "rb") as f:
                species_map = pickle.load(f)
            st.success(f"âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç›¸å¯¹è·¯å¾„ï¼š{MODEL_PATH}ï¼‰")
            return model, species_map
        except Exception as e:
            st.warning(f"âš ï¸ åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{str(e)}ï¼Œå°†é‡æ–°è®­ç»ƒ")
    
    # é‡æ–°è®­ç»ƒæ¨¡å‹
    X, y, species_map = load_and_preprocess_data()
    if X is None:
        return None, None
    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X, y)
    
    # ä¿å­˜æ¨¡å‹ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    with open(MODEL_PATH, "wb") as f:
        pickle.dump(model, f)
    with open(SPECIES_MAP_PATH, "wb") as f:
        pickle.dump(species_map, f)
    st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶ä¿å­˜ï¼ˆç›¸å¯¹è·¯å¾„ï¼š{MODEL_PATH}ï¼‰")
    return model, species_map

# ============================ é¡µé¢é€»è¾‘ï¼ˆé€‚é…ç›¸å¯¹è·¯å¾„ï¼‰ ============================
def render_predict_page():
    global predict_result_species, predict_result_img
    st.header("ä¼é¹…ç‰©ç§é¢„æµ‹ ğŸ“Š")
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    check_species_images()
    
    # å¸ƒå±€
    col_logo, col_form = st.columns([1, 2.5])
    with col_form:
        # è¾“å…¥è¡¨å•
        with st.form("predict_form"):
            island = st.selectbox("æ –æ¯å²›å±¿", ACTUAL_ISLANDS)
            sex = st.selectbox("æ€§åˆ«", ["é›Œæ€§", "é›„æ€§"])
            bill_length = st.number_input("å–™é•¿åº¦ï¼ˆmmï¼‰", 32.0, 60.0, 45.0)
            bill_depth = st.number_input("å–™æ·±åº¦ï¼ˆmmï¼‰", 13.0, 22.0, 17.0)
            flipper_length = st.number_input("ç¿…è†€é•¿åº¦ï¼ˆmmï¼‰", 170.0, 240.0, 200.0)
            body_mass = st.number_input("ä½“é‡ï¼ˆgï¼‰", 2700.0, 6300.0, 4200.0)
            submit = st.form_submit_button("é¢„æµ‹", type="primary")
        
        # åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹
        model, species_map = train_or_load_model()
        if submit and model:
            # æ„é€ è¾“å…¥ç‰¹å¾
            input_data = {
                "å–™é•¿åº¦(mm)": bill_length,
                "å–™æ·±åº¦(mm)": bill_depth,
                "é³é•¿(mm)": flipper_length,
                "ä½“é‡(g)": body_mass
            }
            # è¡¥å……åˆ†ç±»ç‰¹å¾one-hotç¼–ç 
            for feat in model.feature_names_in_:
                if feat.startswith("å²›å±¿_"):
                    input_data[feat] = 1 if feat == f"å²›å±¿_{island}" else 0
                elif feat.startswith("æ€§åˆ«_"):
                    input_data[feat] = 1 if feat == f"æ€§åˆ«_{sex}" else 0
            
            # æ‰§è¡Œé¢„æµ‹
            input_df = pd.DataFrame([[input_data[f] for f in model.feature_names_in_]], 
                                   columns=model.feature_names_in_)
            predict_code = model.predict(input_df)[0]
            predict_result_species = species_map[predict_code]
            predict_result_img, img_msg = get_correct_image(predict_result_species)
            
            # æ˜¾ç¤ºç»“æœ
            st.success(f"ğŸ‰ é¢„æµ‹ç»“æœï¼š{predict_result_species}")
            st.info(f"ğŸ–¼ï¸ {img_msg}")

    # æ˜¾ç¤ºå›¾ç‰‡ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    with col_logo:
        if not submit or not predict_result_img:
            # æœªé¢„æµ‹æ—¶æ˜¾ç¤ºLogoï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            if os.path.exists(LOGO_IMG):
                st.image(LOGO_IMG, width=300, caption="ä¼é¹…åˆ†ç±»å™¨ï¼ˆç›¸å¯¹è·¯å¾„å›¾ç‰‡ï¼‰")
            else:
                st.image("https://picsum.photos/300/300?penguinlogo", width=300, caption="ä¼é¹…åˆ†ç±»å™¨ï¼ˆé»˜è®¤å›¾ï¼‰")
        else:
            # é¢„æµ‹åæ˜¾ç¤ºç‰©ç§å›¾ç‰‡ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            st.image(predict_result_img, width=300, caption=f"é¢„æµ‹ç‰©ç§ï¼š{predict_result_species}")

def render_intro_page():
    st.header("ä¼é¹…åˆ†ç±»å™¨ ğŸ§")
    st.subheader("æ•°æ®é›†ç®€ä»‹ï¼ˆç›¸å¯¹è·¯å¾„ç‰ˆï¼‰")
    
    # æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    st.write(f"- æ•°æ®é›†ç›¸å¯¹è·¯å¾„ï¼š{DATA_PATH}")
    st.write(f"- ä»£ç ä¸æ•°æ®é›†ä½ç½®è¦æ±‚ï¼šå¿…é¡»åœ¨åŒä¸€ç›®å½•ï¼ˆå¦‚D:/streamlit_envï¼‰")
    st.write(f"- åŒ…å«å²›å±¿ï¼š{', '.join(ACTUAL_ISLANDS)}")
    st.write("- é¢„æµ‹ç‰©ç§ï¼šé˜¿å¾·åˆ©ä¼é¹…ã€å¸½å¸¦ä¼é¹…ã€å·´å¸ƒäºšä¼é¹…")
    
    # æ˜¾ç¤ºæ•°æ®é›†æ ·æœ¬ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    if check_file_exists(DATA_PATH, "æ•°æ®é›†"):
        try:
            df_sample = pd.read_csv(DATA_PATH, encoding="gbk").head(5)
            st.dataframe(df_sample, use_container_width=True)
        except:
            st.warning("âš ï¸ æ— æ³•åŠ è½½æ•°æ®é›†æ ·æœ¬")
    
    # ç‰©ç§å›¾é‰´ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    st.subheader("ç‰©ç§å›¾é‰´ï¼ˆç›¸å¯¹è·¯å¾„å›¾ç‰‡ï¼‰")
    col1, col2, col3 = st.columns(3)
    for (species, img_path), col in zip(SPECIES_IMG_MAP.items(), [col1, col2, col3]):
        with col:
            if os.path.exists(img_path):
                st.image(img_path, use_container_width=True)
                st.caption(f"{species}ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰")
            else:
                st.image(f"https://picsum.photos/200/200?{species}", use_container_width=True)
                st.caption(f"{species}ï¼ˆé»˜è®¤å›¾ï¼‰")

# ============================ ä¸»ç¨‹åº ============================
if __name__ == "__main__":
    # åˆå§‹åŒ–æ£€æŸ¥ï¼šä»£ç ä¸æ•°æ®é›†æ˜¯å¦åœ¨åŒä¸€ç›®å½•
    st.markdown("### ğŸ“Œ åˆå§‹åŒ–æ£€æŸ¥ï¼ˆç›¸å¯¹è·¯å¾„ç‰ˆï¼‰")
    if check_file_exists(DATA_PATH, "æ•°æ®é›†"):
        st.success("âœ… æ•°æ®é›†ä¸ä»£ç åœ¨åŒä¸€ç›®å½•ï¼Œå¯æ­£å¸¸è¿è¡Œ")
    else:
        st.error("âŒ æ•°æ®é›†ä¸ä»£ç ä¸åœ¨åŒä¸€ç›®å½•ï¼Œæ— æ³•è¿è¡Œ")
    
    # æ¸²æŸ“ä¾§è¾¹æ 
    st.sidebar.title("åŠŸèƒ½å¯¼èˆª")
    page = st.sidebar.selectbox("é€‰æ‹©é¡µé¢", ["æ•°æ®é›†ç®€ä»‹", "ç‰©ç§é¢„æµ‹"], label_visibility="collapsed")
    
    # æ¸²æŸ“å¯¹åº”é¡µé¢
    if page == "æ•°æ®é›†ç®€ä»‹":
        render_intro_page()
    else:
        render_predict_page()
    
    st.markdown("---")
    st.caption("Â© 2025 ä¼é¹…åˆ†ç±»å™¨ï¼ˆå…¨ç›¸å¯¹è·¯å¾„ç‰ˆï¼‰")
