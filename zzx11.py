import streamlit as st
import pickle
import pandas as pd
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# ============================ å…¨å±€é…ç½®ï¼ˆæ ¸å¿ƒï¼šç‰©ç§-å›¾ç‰‡ç²¾å‡†åŒ¹é…ï¼‰ ============================
st.set_page_config(page_title="ä¼é¹…åˆ†ç±»å™¨", page_icon="ğŸ§", layout="wide")

# æ ¹ç›®å½•è·¯å¾„
BASE_DIR = "D:/streamlit_env"
DATA_PATH = os.path.join(BASE_DIR, "ï¼ˆä¼é¹…è¯†åˆ«æ•°æ®ï¼‰penguins-chinese.csv")
MODEL_PATH = os.path.join(BASE_DIR, "rfc_model.pkl")
SPECIES_MAP_PATH = os.path.join(BASE_DIR, "output_uniques.pkl")

# æ ¸å¿ƒä¿®å¤1ï¼šç‰©ç§-å›¾ç‰‡æ˜ å°„ï¼ˆé€‚é…æ— é‡éŸ³ADELIE.pngï¼Œé™ä½å‘½åéš¾åº¦ï¼‰
SPECIES_IMG_MAP = {
    "é˜¿å¾·åˆ©ä¼é¹…": os.path.join(BASE_DIR, "ADELIE.png"),  # æ— é‡éŸ³ï¼Œæ˜“è¾“å…¥
    "å¸½å¸¦ä¼é¹…": os.path.join(BASE_DIR, "CHINSTRAP.png"),
    "å·´å¸ƒäºšä¼é¹…": os.path.join(BASE_DIR, "GENTOO.png")
}
# å…¶ä»–å›¾ç‰‡è·¯å¾„
LOGO_IMG = os.path.join(BASE_DIR, "right_logo.png")
PENGUINS_ALL_IMG = os.path.join(BASE_DIR, "penguins_all.png")

# æ•°æ®ä¸­å®é™…å²›å±¿ï¼ˆå·²é€‚é…ï¼‰
ACTUAL_ISLANDS = ["æ¯”æ–¯ç§‘ç¾¤å²›", "å¾·é‡Œå§†å²›", "æ‰˜å°”æ£®å²›"]
predict_result_species = None
predict_result_img = None

# ============================ å·¥å…·å‡½æ•°ï¼ˆå¢å¼ºå›¾ç‰‡æ ¡éªŒï¼‰ ============================
def check_species_images():
    """æ£€æŸ¥æ‰€æœ‰ç‰©ç§å›¾ç‰‡æ˜¯å¦å­˜åœ¨ï¼Œè¿”å›ç¼ºå¤±åˆ—è¡¨"""
    missing = []
    for species, img_path in SPECIES_IMG_MAP.items():
        if not os.path.exists(img_path):
            missing.append(f"{species}çš„å›¾ç‰‡ï¼š{os.path.basename(img_path)}")
    return missing

def get_correct_image(species_name):
    """è·å–ç‰©ç§å¯¹åº”çš„æ­£ç¡®å›¾ç‰‡ï¼Œè¿”å›è·¯å¾„å’Œæç¤º"""
    if species_name not in SPECIES_IMG_MAP:
        return None, f"æœªè¯†åˆ«ç‰©ç§ï¼š{species_name}"
    
    img_path = SPECIES_IMG_MAP[species_name]
    if os.path.exists(img_path):
        return img_path, f"æˆåŠŸåŠ è½½{species_name}å›¾ç‰‡"
    else:
        # ä¿®å¤2ï¼šå ä½å›¾ç”¨ä¼é¹…ç›¸å…³å›¾ï¼Œè€Œéå²©çŸ³
        default_img = f"https://picsum.photos/300/300?{species_name}"
        return default_img, f"ç¼ºå¤±{species_name}å›¾ç‰‡ï¼š{os.path.basename(img_path)}ï¼Œå·²ç”¨é»˜è®¤å›¾æ›¿ä»£"

# ============================ æ ¸å¿ƒåŠŸèƒ½å‡½æ•°ï¼ˆæ— ä¿®æ”¹ï¼Œç¡®ä¿ç¨³å®šï¼‰ ============================
def load_and_preprocess_data():
    global ACTUAL_ISLANDS
    if not os.path.exists(DATA_PATH):
        st.error(f"âŒ æœªæ‰¾åˆ°æ•°æ®é›†ï¼š{DATA_PATH}")
        return None, None, None
    
    try:
        df = pd.read_csv(DATA_PATH, encoding="gbk")
        st.success("âœ… è¯»å–æ•°æ®é›†ï¼ˆç¼–ç ï¼šgbkï¼‰")
    except:
        st.error("âŒ æ•°æ®é›†è¯»å–å¤±è´¥ï¼Œè¯·ç¡®è®¤ç¼–ç ä¸ºgbk")
        return None, None, None
    
    # æ•°æ®æ¸…æ´—ä¸å²›å±¿åŒæ­¥
    df = df.dropna(subset=["ä¼é¹…çš„ç§ç±»", "ä¼é¹…æ –æ¯çš„å²›å±¿", "å–™çš„é•¿åº¦", "å–™çš„æ·±åº¦", "ç¿…è†€çš„é•¿åº¦", "èº«ä½“è´¨é‡", "æ€§åˆ«"])
    data_islands = df["ä¼é¹…æ –æ¯çš„å²›å±¿"].unique()
    if not set(data_islands).issubset(set(ACTUAL_ISLANDS)):
        ACTUAL_ISLANDS = list(data_islands)
        st.info(f"â„¹ï¸ åŒæ­¥æ•°æ®ä¸­çš„å²›å±¿ï¼š{ACTUAL_ISLANDS}")
    
    # åˆ—åæ˜ å°„ä¸ç¼–ç 
    df.rename(columns={
        "ä¼é¹…çš„ç§ç±»": "ç‰©ç§", "ä¼é¹…æ –æ¯çš„å²›å±¿": "å²›å±¿",
        "å–™çš„é•¿åº¦": "å–™é•¿åº¦(mm)", "å–™çš„æ·±åº¦": "å–™æ·±åº¦(mm)",
        "ç¿…è†€çš„é•¿åº¦": "é³é•¿(mm)", "èº«ä½“è´¨é‡": "ä½“é‡(g)"
    }, inplace=True)
    
    X = pd.get_dummies(df[["å–™é•¿åº¦(mm)", "å–™æ·±åº¦(mm)", "é³é•¿(mm)", "ä½“é‡(g)", "å²›å±¿", "æ€§åˆ«"]], 
                      columns=["å²›å±¿", "æ€§åˆ«"], drop_first=False)
    le = LabelEncoder()
    y = le.fit_transform(df["ç‰©ç§"])
    species_map = {idx: name for idx, name in enumerate(le.classes_)}
    
    return X, y, species_map

def train_or_load_model():
    if os.path.exists(MODEL_PATH) and os.path.exists(SPECIES_MAP_PATH):
        try:
            with open(MODEL_PATH, "rb") as f:
                model = pickle.load(f)
            with open(SPECIES_MAP_PATH, "rb") as f:
                species_map = pickle.load(f)
            # éªŒè¯å²›å±¿ç‰¹å¾
            model_islands = [f for f in model.feature_names_in_ if f.startswith("å²›å±¿_")]
            if set(model_islands) != set([f"å²›å±¿_{i}" for i in ACTUAL_ISLANDS]):
                st.warning("âš ï¸ æ¨¡å‹å²›å±¿ç‰¹å¾ä¸åŒ¹é…ï¼Œé‡æ–°è®­ç»ƒ")
                raise Exception()
            st.success("âœ… åŠ è½½æ¨¡å‹æˆåŠŸ")
            return model, species_map
        except:
            st.warning("âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé‡æ–°è®­ç»ƒ")
    
    X, y, species_map = load_and_preprocess_data()
    if X is None:
        return None, None
    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X, y)
    with open(MODEL_PATH, "wb") as f:
        pickle.dump(model, f)
    with open(SPECIES_MAP_PATH, "wb") as f:
        pickle.dump(species_map, f)
    st.success("âœ… æ¨¡å‹è®­ç»ƒå¹¶ä¿å­˜æˆåŠŸ")
    return model, species_map

# ============================ é¡µé¢é€»è¾‘ï¼ˆå¢å¼ºå›¾ç‰‡æç¤ºï¼‰ ============================
def render_predict_page():
    global predict_result_species, predict_result_img
    st.header("ä¼é¹…ç‰©ç§é¢„æµ‹ ğŸ“Š")
    
    # ä¿®å¤3ï¼šé¢„æµ‹å‰å…ˆæç¤ºç¼ºå¤±å›¾ç‰‡
    missing_imgs = check_species_images()
    if missing_imgs:
        st.warning("âš ï¸ æ ¹ç›®å½•ç¼ºå°‘ä»¥ä¸‹ç‰©ç§å›¾ç‰‡ï¼ˆä¼šå½±å“æ˜¾ç¤ºï¼‰ï¼š")
        for img in missing_imgs:
            st.write(f"- {img}")
    
    col_logo, col_form = st.columns([1, 2.5])
    with col_form:
        with st.form("predict_form"):
            island = st.selectbox("æ –æ¯å²›å±¿", ACTUAL_ISLANDS)
            sex = st.selectbox("æ€§åˆ«", ["é›Œæ€§", "é›„æ€§"])
            bill_length = st.number_input("å–™é•¿åº¦ï¼ˆmmï¼‰", 32.0, 60.0, 45.0)
            bill_depth = st.number_input("å–™æ·±åº¦ï¼ˆmmï¼‰", 13.0, 22.0, 17.0)
            flipper_length = st.number_input("ç¿…è†€é•¿åº¦ï¼ˆmmï¼‰", 170.0, 240.0, 200.0)
            body_mass = st.number_input("ä½“é‡ï¼ˆgï¼‰", 2700.0, 6300.0, 4200.0)
            submit = st.form_submit_button("é¢„æµ‹", type="primary")
        
        model, species_map = train_or_load_model()
        if submit and model:
            # æ„é€ è¾“å…¥ç‰¹å¾
            input_data = {"å–™é•¿åº¦(mm)": bill_length, "å–™æ·±åº¦(mm)": bill_depth, 
                          "é³é•¿(mm)": flipper_length, "ä½“é‡(g)": body_mass}
            for feat in model.feature_names_in_:
                if feat.startswith("å²›å±¿_"):
                    input_data[feat] = 1 if feat == f"å²›å±¿_{island}" else 0
                elif feat.startswith("æ€§åˆ«_"):
                    input_data[feat] = 1 if feat == f"æ€§åˆ«_{sex}" else 0
            
            input_df = pd.DataFrame([[input_data[f] for f in model.feature_names_in_]], 
                                   columns=model.feature_names_in_)
            predict_code = model.predict(input_df)[0]
            predict_result_species = species_map[predict_code]
            
            # ä¿®å¤4ï¼šè·å–å›¾ç‰‡å¹¶æ˜¾ç¤ºæç¤º
            predict_result_img, img_msg = get_correct_image(predict_result_species)
            st.success(f"ğŸ‰ é¢„æµ‹ç»“æœï¼š{predict_result_species}")
            st.info(f"ğŸ–¼ï¸ {img_msg}")  # æç¤ºå›¾ç‰‡åŠ è½½çŠ¶æ€

    with col_logo:
        if not submit or not predict_result_img:
            st.image(LOGO_IMG if os.path.exists(LOGO_IMG) else "https://picsum.photos/300/300?penguinlogo", 
                     width=300, caption="ä¼é¹…åˆ†ç±»å™¨")
        else:
            st.image(predict_result_img, width=300, caption=f"é¢„æµ‹ç‰©ç§ï¼š{predict_result_species}")

def render_intro_page():
    st.header("ä¼é¹…åˆ†ç±»å™¨ ğŸ§")
    st.subheader("æ•°æ®é›†ç®€ä»‹")
    st.write(f"- åŒ…å«å²›å±¿ï¼š{', '.join(ACTUAL_ISLANDS)}")
    st.write("- é¢„æµ‹ç‰©ç§ï¼šé˜¿å¾·åˆ©ä¼é¹…ã€å¸½å¸¦ä¼é¹…ã€å·´å¸ƒäºšä¼é¹…")
    
    # æ˜¾ç¤ºæ•°æ®é›†æ ·æœ¬
    if os.path.exists(DATA_PATH):
        df_sample = pd.read_csv(DATA_PATH, encoding="gbk").head(5)
        st.dataframe(df_sample, use_container_width=True)
    
    # æ˜¾ç¤ºç‰©ç§å›¾é‰´
    st.subheader("ç‰©ç§å›¾é‰´")
    col1, col2, col3 = st.columns(3)
    for (species, img_path), col in zip(SPECIES_IMG_MAP.items(), [col1, col2, col3]):
        with col:
            img = img_path if os.path.exists(img_path) else f"https://picsum.photos/200/200?{species}"
            st.image(img, use_container_width=True)
            st.caption(species)

# ============================ ä¸»ç¨‹åº ============================
if __name__ == "__main__":
    st.sidebar.title("åŠŸèƒ½å¯¼èˆª")
    page = st.sidebar.selectbox("é€‰æ‹©é¡µé¢", ["æ•°æ®é›†ç®€ä»‹", "ç‰©ç§é¢„æµ‹"], label_visibility="collapsed")
    
    if page == "æ•°æ®é›†ç®€ä»‹":
        render_intro_page()
    else:
        render_predict_page()
    
    st.markdown("---")
    st.caption("Â© 2025 ä¼é¹…åˆ†ç±»å™¨ï¼ˆå›¾ç‰‡ä¿®å¤ç‰ˆï¼‰")
